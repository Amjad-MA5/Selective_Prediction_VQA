{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute risk bound and theta with Selection with Guaranteed Risk (SGR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://arxiv.org/pdf/1705.08500 Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_control import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Confidence Scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1 : **Maxprob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def max_occurence(labels):\n",
    "    count = Counter(labels)\n",
    "    max_num = max(count, key=count.get)\n",
    "    return max_num\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        \n",
    "        logits = torch.from_numpy(logits)\n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() != max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & 0.0078 & 0.2677 & 0.0080 & 0.2669 & 0.0100  \\\\\n",
      "0.02 & 0.0173 & 0.3615 & 0.0176 & 0.3642 & 0.0200  \\\\\n",
      "0.10 & 0.0957 & 0.6788 & 0.0959 & 0.6775 & 0.1000  \\\\\n",
      "0.15 & 0.1453 & 0.8058 & 0.1464 & 0.8070 & 0.1500  \\\\\n",
      "0.20 & 0.1950 & 0.9119 & 0.1926 & 0.9111 & 0.2000  \\\\\n",
      "0.25 & 0.2441 & 1.0000 & 0.2445 & 1.0000 & 0.2492  \\\\\n",
      "0.30 & 0.2450 & 1.0000 & 0.2436 & 1.0000 & 0.2502  \\\\\n",
      "1.00 & 0.2453 & 1.0000 & 0.2434 & 1.0000 & 0.2504  \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_max_prob = {}\n",
    "risk_stars = [0.01, 0.02, 0.1, 0.15, 0.20, 0.25,0.30, 1.0] # desired risk\n",
    "delta = 0.001 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= True)\n",
    "    risk_dict_max_prob[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [0.99085826, 0.019990195521006792],\n",
       " '0.1': [0.7031023, 0.0999923430674681],\n",
       " '0.15': [0.51198816, 0.14999186544652277],\n",
       " '0.2': [0.28016168, 0.19999890216158067],\n",
       " '0.25': [0.030047635, 0.24999369884229788],\n",
       " '0.3': [0.022310337, 0.24959095036491086],\n",
       " '1.0': [0.022311127, 0.24913977406440627]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: **Vector Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/teamspace/studios/this_studio/Selective_Prediction_VQA\")\n",
    "from calibration_methods import calibrator as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibrator(path, calibrator_type = \"vector_calibrator\", device = 'cpu'):\n",
    "    dict = torch.load(path)\n",
    "    if calibrator_type == \"vector_calibrator\":\n",
    "        cali = cal.VectorScaling(bias=dict['biasFlag'], \n",
    "                                 weights= dict['weights'],\n",
    "                                 num_label = dict['num_label'],\n",
    "                                 device=device,\n",
    "                                 print_verbose= False)\n",
    "        cali.temperature = dict['temperature']\n",
    "        cali.bias = dict['bias']\n",
    "    else:\n",
    "        #todo\n",
    "        return None\n",
    "    return cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/calibration_methods/scaling/vector_calibrator.pt\"\n",
    "cali = load_calibrator(path, calibrator_type = \"vector_calibrator\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/predictions/logits_and_labels/\"\n",
    "NUM_BATCH = 2139\n",
    "residuals = []\n",
    "kappa = []\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for batch_no in range(NUM_BATCH):\n",
    "    file_name = \"Logits_and_labels\" + str(batch_no) + \".pt\"\n",
    "    data = torch.load(data_path + file_name)\n",
    "    \n",
    "    for logits, labels in zip(data['logits'], data['labels']):\n",
    "        if(len(labels)) == 0:\n",
    "            continue\n",
    "        logits = cali.calibrate(logits)\n",
    "        logits = torch.from_numpy(logits)\n",
    "        \n",
    "        prob = softmax(logits)\n",
    "        # print(prob)\n",
    "        # print(torch.max(prob).numpy())\n",
    "        # prob.to('cpu')\n",
    "        kappa.append(torch.max(prob).numpy())\n",
    "        idx = torch.argmax(prob)\n",
    "        # print(prob[0][idx])\n",
    "        # print(labels)\n",
    "        residuals.append(idx.item() != max_occurence(labels))\n",
    "        # print(kappa)\n",
    "        # print(residuals)\n",
    "        # break\n",
    "    # break\n",
    "        \n",
    "    \n",
    "# kappa, residuals = sort(kappa, residuals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 & 0.0000 & 0.0000 & 0.0305 & 0.4579 & 0.9999  \\\\\n",
      "0.10 & 0.0957 & 0.6769 & 0.0936 & 0.6746 & 0.1000  \\\\\n",
      "0.15 & 0.1452 & 0.7933 & 0.1461 & 0.7934 & 0.1500  \\\\\n",
      "0.20 & 0.1950 & 0.9020 & 0.1977 & 0.9016 & 0.2000  \\\\\n",
      "0.25 & 0.2449 & 0.9991 & 0.2436 & 0.9990 & 0.2500  \\\\\n",
      "0.30 & 0.2458 & 1.0000 & 0.2440 & 1.0000 & 0.2509  \\\\\n",
      "1.00 & 0.2447 & 1.0000 & 0.2451 & 0.9999 & 0.2498  \\\\\n"
     ]
    }
   ],
   "source": [
    "kappa = np.array(kappa)\n",
    "residuals = np.array(residuals)\n",
    "risk_dict_vec_scal = {}\n",
    "risk_stars = [0.02, 0.1, 0.15, 0.20, 0.25,0.30, 1.0] # desired risk\n",
    "delta = 0.001 ## confidence\n",
    "for desired_risk in risk_stars:\n",
    "    bound_cal = risk_control()\n",
    "    [theta, b_star] = bound_cal.bound(desired_risk, delta, kappa, residuals, split= True)\n",
    "    risk_dict_vec_scal[str(desired_risk)] = [theta, b_star]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.02': [1.0, 0.9999411106109619],\n",
       " '0.1': [0.998445, 0.09999037189914387],\n",
       " '0.15': [0.9656034, 0.14999588742648362],\n",
       " '0.2': [0.77072865, 0.19999776104858114],\n",
       " '0.25': [0.2225435, 0.24999369884229788],\n",
       " '0.3': [0.1459447, 0.24969663580229495],\n",
       " '1.0': [0.14571935, 0.25128186931671803]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_dict_vec_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risk_dict = {\n",
    "    'max_prob' : risk_dict_max_prob,\n",
    "    'vector_scaling_calibration' : risk_dict_vec_scal\n",
    "}\n",
    "path = \"/teamspace/studios/this_studio/Selective_Prediction_VQA/risk_bounds/\"\n",
    "torch.save(risk_dict, path + \"risk_bound.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51335"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209608"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24490954543719706"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(residuals)/residuals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
